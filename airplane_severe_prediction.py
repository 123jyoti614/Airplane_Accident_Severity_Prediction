# -*- coding: utf-8 -*-
"""airplane_severe_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sR18gE61LSqoa-3p0eIoPk77AC4J6czo
"""

import numpy as np
import pandas as pd

train=pd.read_csv('/content/train.csv')
test=pd.read_csv('/content/test.csv')

train.head(10)

train.isnull().sum()

train.shape

"""Drop Accident_ID (not useful for prediction).

Convert Accident_Type_Code to categorical (use one-hot or label encoding).

Check for missing values and handle them (mean/mode imputation or ML-based).

Scale numerical features if using models sensitive to scale (e.g., Logistic Regression, SVM).

Encode Severity for model training (LabelEncoder or one-hot if needed for deep learning).
"""

train.info()

print(train['Severity'].value_counts())

train=train.drop(columns=['Accident_ID'])
test_id=test['Accident_ID']
test=test.drop(columns=['Accident_ID'])

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
train['Severity']=le.fit_transform(train['Severity'])

#combine train and test data
combined=pd.concat([train.drop(columns=['Severity']),test],axis=0)

#encode accident type
combined=pd.get_dummies(combined,columns=['Accident_Type_Code'])

combined.fillna(combined.mean(),inplace=True)

#target class imbalance
X=combined.iloc[:len(train),:]
y=train['Severity']
X_test=combined.iloc[len(train):,:]

from imblearn.over_sampling import SMOTE

# SMOTE resampling
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

print("Before SMOTE:", np.bincount(y))
print("After SMOTE:", np.bincount(y_resampled))

y_res_cat = to_categorical(y_resampled, num_classes=4)

from sklearn.model_selection import train_test_split
#from sklear.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
#from sklearn.xgboost import XGBClassifier
from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,classification_report

X_train,X_val,y_train,y_val=train_test_split(X_resampled,y_res_cat,random_state=42,stratify=y_resampled)

rf=RandomForestClassifier(random_state=42)
rf.fit(X_train,y_train)
y_pred=rf.predict(X_val)

print("Evaluation for Random Forest:")
print(confusion_matrix(y_val, y_pred))
print(classification_report(y_val, y_pred, target_names=le.classes_))

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
X_train=scaler.fit_transform(X_train)
X_val=scaler.transform(X_val)
X_test_scaled=scaler.transform(X_test)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Dropout
from tensorflow.keras.utils import to_categorical

model=Sequential()
model.add(Dense(128,input_shape=(X_train.shape[1],),activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(64,activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(32,activation='relu'))
model.add(Dense(4,activation='softmax'))
model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])
model.summary()

history=model.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=20,batch_size=32)

# Predict on validation set
val_preds = model.predict(X_val)
val_preds_labels = np.argmax(val_preds, axis=1)
true_labels = np.argmax(y_val, axis=1)

print("Confusion Matrix:")
print(confusion_matrix(true_labels, val_preds_labels))

print("\nClassification Report:")
print(classification_report(true_labels, val_preds_labels, target_names=le.classes_))

